{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The corpora with NLTK\n",
    "The NLTK corpus is a massive dump of all kinds of natural language data sets that are definitely worth taking a look at.\n",
    "\n",
    "Almost all of the files in the NLTK corpus follow the same rules for accessing them by using the NLTK module, but nothing is magical about them. These files are plain text files for the most part, some are XML and some are other formats, but they are all accessible by you manually, or via the module and Python. Let's talk about viewing them manually.\n",
    "\n",
    "Depending on your installation, your nltk_data directory might be hiding in a multitude of locations. To figure out where it is, head to your Python directory, where the NLTK module is. If you do not know where that is, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run that, and the output will be the location of the NLTK module's __init__.py. Head into the NLTK directory, and then look for the data.py file.\n",
    "\n",
    "The important blurb of code is:\n",
    "```\n",
    "if sys.platform.startswith('win'):\n",
    "    # Common locations on Windows:\n",
    "    path += [\n",
    "        str(r'C:\\nltk_data'), str(r'D:\\nltk_data'), str(r'E:\\nltk_data'),\n",
    "        os.path.join(sys.prefix, str('nltk_data')),\n",
    "        os.path.join(sys.prefix, str('lib'), str('nltk_data')),\n",
    "        os.path.join(os.environ.get(str('APPDATA'), str('C:\\\\')), str('nltk_data'))\n",
    "    ]\n",
    "else:\n",
    "    # Common locations on UNIX & OS X:\n",
    "    path += [\n",
    "        str('/usr/share/nltk_data'),\n",
    "        str('/usr/local/share/nltk_data'),\n",
    "        str('/usr/lib/nltk_data'),\n",
    "        str('/usr/local/lib/nltk_data')\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, you can see the various possible directories for the nltk_data. If you're on Windows, chances are it is in your appdata, in the local directory. To get there, you will want to open your file browser, go to the top, and type in %appdata%\n",
    "\n",
    "Next click on roaming, and then find the nltk_data directory. In there, you will have your corpora file. The full path is something like: \n",
    "C:\\Users\\yourname\\AppData\\Roaming\\nltk_data\\corpora\n",
    "\n",
    "Within here, you have all of the available corpora, including things like books, chat logs, movie reviews, and a whole lot more.\n",
    "\n",
    "Now, we're going to talk about accessing these documents via NLTK. As you can see, these are mostly text documents, so you could just use normal Python code to open and read documents. That said, the NLTK module has a few nice methods for handling the corpus, so you may find it useful to use their methology. Here's an example of us opening the Gutenberg Bible, and reading the first few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The King James Bible]\n",
      "\n",
      "The Old Testament of the King James Bible\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth.\n",
      "1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep.\n",
      "And the Spirit of God moved upon the face of the\n",
      "waters.\n",
      "1:3 And God said, Let there be light: and there was light.\n",
      "1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# sample text\n",
    "sample = gutenberg.raw(\"bible-kjv.txt\")\n",
    "\n",
    "tok = sent_tokenize(sample)\n",
    "\n",
    "for x in range(5):\n",
    "    print(tok[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more advanced data sets in here is \"wordnet.\" Wordnet is a collection of words, definitions, examples of their use, synonyms, antonyms, and more. We'll dive into using wordnet next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
