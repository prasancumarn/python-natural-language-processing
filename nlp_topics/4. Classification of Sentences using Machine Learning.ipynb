{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CODE_LOC = 'D:\\\\Git\\\\python-natural-language-processing\\\\nlp_in_short\\\\'   # !! Modify to path to \"features.py\" folder lcoation\n",
    "DATA_LOC = 'D:\\\\Git\\\\python-natural-language-processing\\\\nlp_in_short\\\\sentences.csv'  # !! Modify this to the CSV data location\n",
    "\n",
    "sentences = pd.read_csv(filepath_or_buffer = DATA_LOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry, I don't know about the weather.</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That is a tricky question to answer.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does OCM stand for</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAX is a Mobile Application Accelerator</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can a dog see in colour?</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how are you</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you deploy a MySQL database in the Oracle c...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>who is dominic Fakename</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what's the weather like today?</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can the OCM host non Oracle software stacks?</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            SENTENCE CLASS\n",
       "0             Sorry, I don't know about the weather.     S\n",
       "1               That is a tricky question to answer.     C\n",
       "2                            What does OCM stand for     Q\n",
       "3            MAX is a Mobile Application Accelerator     S\n",
       "4                           Can a dog see in colour?     Q\n",
       "5                                        how are you     C\n",
       "6  If you deploy a MySQL database in the Oracle c...     Q\n",
       "7                            who is dominic Fakename     Q\n",
       "8                     what's the weather like today?     C\n",
       "9       Can the OCM host non Oracle software stacks?     Q"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering - A Non-Standard, Bespoke Approch\n",
    "\n",
    "Chapter 6 of the NLTK Book has a great deal of background and worked examples for classifying text using machine learning algorithms such as Naive Bayes Classifiers. A different bespoke approach involving home-grown feature engineering and a scikit-learn Random Forest model is outlined in this note.\n",
    "\n",
    "The code snippet below is an example of taking a sentence and extracting sets of POS-tag Triples from it. We can use this approach for building up features from a sentence by counting occurances of triple-patterns (or other POS-tag patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words mapped to Part of Speech Tags: [('Can', 'MD'), ('a', 'DT'), ('dog', 'NN'), ('see', 'NN'), ('in', 'IN'), ('Colour', 'NNP'), ('?', '.')]\n",
      "PoS Tags: ['MD', 'DT', 'NN', 'NN', 'IN', 'NNP', '.']\n",
      "Sequence of triples: ['MD-DT-NN', 'DT-NN-NN', 'NN-NN-IN', 'NN-IN-NNP']\n"
     ]
    }
   ],
   "source": [
    "# Extract some patterns of PoS sequences \n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "list_of_triple_strings = [] #triple sequence of PoS tags\n",
    "sentence = \"Can a dog see in Colour?\"\n",
    "\n",
    "sentence_parsed = word_tokenize(sentence)\n",
    "#print(sentence_parsed)\n",
    "pos_tags = nltk.pos_tag(sentence_parsed)\n",
    "#print(pos_tags)\n",
    "pos = [ i[1] for i in pos_tags ]\n",
    "print(\"Words mapped to Part of Speech Tags:\",pos_tags)\n",
    "print(\"PoS Tags:\", pos)\n",
    "\n",
    "n = len(pos)\n",
    "for i in range(0,n-3):\n",
    "    t = \"-\".join(pos[i:i+3]) # pull out 3 list item from counter, convert to string\n",
    "    list_of_triple_strings.append(t)\n",
    "    \n",
    "print(\"Sequence of triples:\", list_of_triple_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features\n",
    "\n",
    "After pre-processing the sentences (using the approach above) we can get a set of triples for Questions, Chat, Statements. There will be a lot of intersection, but hopefully some clear patterns\n",
    "## The features.py Features Generator\n",
    "This is a custom Python module to extract features from a sentence, written for this ChatBot demo.\n",
    "\n",
    "features.py is located here: https://github.com/edbullen/NLPBot/releases/download/SupportingFiles/features.py\n",
    "\n",
    "Just\n",
    "\n",
    "`import features`\n",
    "\n",
    "and call\n",
    "\n",
    "`features = features_dict(id,sentence, c)`\n",
    "\n",
    "to extract a dictionary of features for the given sentence.\n",
    "\n",
    "* The \"id\" can be any arbirtary ID value - it just get s passed in and passout as an ID identifier in the resultant dictionary.\n",
    "* The \"c\" value can also be any arbitrary value representing the Class label - the idea is to supply an appropriate label so that the dict that is passed back has all the necessary information in it.\n",
    "\n",
    "The actual features that are generated and the logic behind how this is done is all hard-coded in features.py (it is not paramaterised - a potential enhancement that could be added)\n",
    "\n",
    "#### features.py POS Triples Extract\n",
    "\n",
    "The features.py module includes a function\n",
    "`get_triples(pos)`\n",
    "which returns a string of the form \"POS-POS-POS\" where \"POS\" is a Part-Of-Speech tag.\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can a dog see in colour\n",
      "['MD-DT-NN', 'DT-NN-NN', 'NN-NN-IN', 'NN-IN-NN']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(CODE_LOC)\n",
    "import features\n",
    "\n",
    "sentence = \"Can a dog see in colour?\"\n",
    "\n",
    "sentence = features.strip_sentence(sentence)\n",
    "print(sentence)\n",
    "\n",
    "pos = features.get_pos(sentence)\n",
    "triples = features.get_triples(pos)\n",
    "\n",
    "print(triples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
